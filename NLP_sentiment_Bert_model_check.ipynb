{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCwmpDpHY7LwLS0koYZmkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeSN-Lab/DeepArc/blob/main/NLP_sentiment_Bert_model_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdT2VpGh4tlb",
        "outputId": "b9c8242a-dbb4-44af-a048-1f949a211c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "dtppTfv04u-g"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 인코더 레이어 개수 확인\n",
        "num_layers = len(model.bert.encoder.layer)\n",
        "print(f\"Original number of layers: {num_layers}\")\n",
        "\n",
        "# 마지막 인코더 레이어 제거\n",
        "model.bert.encoder.layer = model.bert.encoder.layer[:-1]\n",
        "\n",
        "# 첫번째 인코더 레이어 제거\n",
        "# model.bert.encoder.layer = model.bert.encoder.layer[1:]\n",
        "\n",
        "# 수정된 인코더 레이어 개수 확인\n",
        "new_num_layers = len(model.bert.encoder.layer)\n",
        "print(f\"New number of layers: {new_num_layers}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyFMEX9X4xdQ",
        "outputId": "ba066a18-9ba0-4a3f-fbd6-7fdc238a66e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of layers: 12\n",
            "New number of layers: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트를 위한 입력 문장\n",
        "text = \"It's bad!\"\n",
        "\n",
        "# 토큰화 및 모델에 입력하기 위한 형식으로 변환\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# 수정된 모델로 예측\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# 출력 로짓 확인\n",
        "print(outputs.logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvIVYccK4ztA",
        "outputId": "b9c1cb9b-20b4-43cc-8ea1-46e1d5b08a0b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2359,  0.6371,  1.0244, -0.3304, -1.2896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# 테스트 문장\n",
        "text = \"It's bad!\"\n",
        "\n",
        "# 토큰화 및 모델에 입력하기 위한 형식으로 변환\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# 수정된 모델로 예측\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# 로짓을 확률로 변환\n",
        "probabilities = softmax(outputs.logits, dim=-1)\n",
        "\n",
        "print(\"Probabilities:\", probabilities)\n",
        "\n",
        "# 확률 분포를 바탕으로 예측 점수 계산\n",
        "predicted_score = torch.argmax(probabilities, dim=-1) + 1\n",
        "\n",
        "print(f\"Predicted score: {predicted_score.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pIkSAJG5_gL",
        "outputId": "b7fb1b90-da39-49da-89ac-8084c9c20a52"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities: tensor([[0.1825, 0.2726, 0.4016, 0.1036, 0.0397]])\n",
            "Predicted score: 3\n"
          ]
        }
      ]
    }
  ]
}